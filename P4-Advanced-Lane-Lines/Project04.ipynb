{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from math import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calibrate_camera(cal_images, nx, ny):\n",
    "    objpoints = []  # 3D points\n",
    "    imgpoints = []  # 2D points\n",
    "\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    fname = cal_images[0]\n",
    "    for fname in cal_images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "def camera_setup():\n",
    "    cal_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    nx, ny = 9, 6\n",
    "    cam_mtx, cam_dist = calibrate_camera(cal_images, nx, ny)\n",
    "    return cam_mtx, cam_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(image):\n",
    "    img_size = image.shape\n",
    "    src = np.array([[565. /1280.*img_size[1], 455./720.*img_size[0]],\n",
    "                    [725. /1280.*img_size[1], 455./720.*img_size[0]],\n",
    "                    [1130./1280.*img_size[1], 720./720.*img_size[0]],\n",
    "                    [190. /1280.*img_size[1], 720./720.*img_size[0]]], np.float32)\n",
    "\n",
    "    dst = np.array([[300. /1280.*img_size[1], 0.  /720.*img_size[0]],\n",
    "                    [1000./1280.*img_size[1], 0.  /720.*img_size[0]],\n",
    "                    [1000./1280.*img_size[1], 720./720.*img_size[0]],\n",
    "                    [300. /1280.*img_size[1], 720./720.*img_size[0]]], np.float32)\n",
    "\n",
    "    warp_m = cv2.getPerspectiveTransform(src, dst)\n",
    "    warp_minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return warp_m, warp_minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sobel(gray, orient='x', sobel_kernel=3):\n",
    "    return cv2.Sobel(gray, cv2.CV_64F, orient == 'x', orient == 'y', ksize=sobel_kernel)\n",
    "\n",
    "def abs_sobel_thresh(sobel, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    retval, output = cv2.threshold(scaled_sobel, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return output\n",
    "\n",
    "def mag_thresh(sobelx, sobely, thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    mag_sobel = (255*mag_sobel/np.max(mag_sobel)).astype(np.uint8)\n",
    "\n",
    "    retval, output = cv2.threshold(mag_sobel, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return output\n",
    "\n",
    "def dir_threshold(sobelx, sobely, thresh=(0, np.pi/2)):\n",
    "    # Here I'm suppressing annoying error messages\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        absgraddir = (np.absolute(np.arctan(sobely/sobelx)))\n",
    "        dir_binary =  np.zeros_like(absgraddir, dtype=np.uint8)\n",
    "        dir_binary[(absgraddir > thresh[0]) & (absgraddir < thresh[1])] = 1\n",
    "\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_edges(image, ksize = 11):\n",
    "    blur = cv2.GaussianBlur(image, (ksize, ksize), 0)\n",
    "    gray = cv2.equalizeHist(cv2.cvtColor(blur.astype(np.uint8), cv2.COLOR_RGB2GRAY))\n",
    "#     hls = cv2.cvtColor(blur.astype(np.uint8), cv2.COLOR_RGB2HLS)\n",
    "\n",
    "#     h = hls[:,:,0]\n",
    "#     l = hls[:,:,1]\n",
    "#     s = hls[:,:,2]\n",
    "    sobelx = sobel(gray, orient='x', sobel_kernel=ksize)\n",
    "    gradx = abs_sobel_thresh(sobelx, thresh=(60, 70))\n",
    "\n",
    "    sobely = sobel(gray, orient='y', sobel_kernel=ksize)\n",
    "    grady = abs_sobel_thresh(sobely, thresh=(50, 120))\n",
    "    mag_binary = mag_thresh(sobelx, sobely, thresh=(50, 100))\n",
    "    _, gray_binary = cv2.threshold(gray.astype('uint8'), 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Check if gradx has sufficient data, else use magnitude\n",
    "    total_px = gradx.shape[0]*gradx.shape[1]/2\n",
    "    if cv2.countNonZero(gradx[gradx.shape[0]/2:])/total_px < 0.01:\n",
    "        mask_two = mag_binary\n",
    "    else:\n",
    "        mask_two = gradx\n",
    "    \n",
    "#     yellow_mask =(cv2.inRange(h, 18, 22)/255.0).astype(np.uint8)\n",
    "    yellow = (np.array([160, 128, 0]), np.array([255, 255, 128]))\n",
    "\n",
    "    yellow_mask = (cv2.inRange(undist, yellow[0], yellow[1])/255.0).astype(np.uint8)\n",
    "#     white_mask = cv2.inRange(l, 150, 200).astype(np.uint8)/255.0\n",
    "\n",
    "    combined_binary = np.zeros_like(gray_binary)\n",
    "    combined_binary = np.clip(cv2.bitwise_and(gray_binary, cv2.bitwise_or(mask_two, yellow_mask)), 0, 1).astype('uint8')\n",
    "    \n",
    "#     plt.subplot(2, 3, 1)\n",
    "#     plt.imshow(yellow_mask, cmap='gray')\n",
    "#     plt.subplot(2, 3, 2)\n",
    "#     plt.imshow(white_mask, cmap='gray')\n",
    "#     plt.subplot(2, 3, 3)\n",
    "#     plt.imshow(mask_two, cmap='gray')\n",
    "#     plt.subplot(2, 3, 4)\n",
    "#     plt.imshow(gray_binary, cmap='gray')\n",
    "#     plt.subplot(2, 3, 5)\n",
    "#     plt.imshow(mag_binary, cmap='gray')\n",
    "#     plt.subplot(2, 3, 6)\n",
    "#     plt.imshow(combined_binary, cmap='gray')\n",
    "\n",
    "\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam_mtx, cam_dist = camera_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = mpimage.imread('test_images/test2b.jpg')\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-243-91522a295909>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-243-91522a295909>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    pts cv2.findNonZero(lanes)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "undist = cv2.undistort(image, cam_mtx, cam_dist, None, cam_mtx)\n",
    "\n",
    "yellow = (np.array([160, 128, 0]), np.array([255, 255, 128]))\n",
    "hls = cv2.cvtColor(undist, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "edges = find_edges(undist)\n",
    "warp_m, warp_minv = get_perspective_transform(edges)\n",
    "lanes = cv2.warpPerspective(edges, warp_m, (edges.shape[1], edges.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "plt.rcParams['figure.figsize'] = figsize=(10,12)\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(lanes, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(undist, cmap='gray')\n",
    "\n",
    "pts cv2.findNonZero(lanes)\n",
    "print(pts.reshape((-1,2)))\n",
    "# base_pts = find_base_points(lanes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "import collections\n",
    "from itertools import chain, repeat\n",
    "    \n",
    "class Lane():\n",
    "    def __init__(self, base_pt, img_size):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = collections.deque(maxlen=10)\n",
    "        self.recent_yfitted = collections.deque(maxlen=10)\n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None   \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        self.current_xfit = None\n",
    "        self.roi_mask = None\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.base_pt = base_pt\n",
    "        \n",
    "        self.yvals = np.linspace(0, img_size[0], 101)\n",
    "        self.mask = np.ones(img_size, dtype=np.uint8)*255\n",
    "    \n",
    "    def add_lane_pixels(self, x, y):\n",
    "        # Use all pixels from previous detections for curve fit\n",
    "        x_hist = list(chain(*self.recent_xfitted, x))\n",
    "        y_hist = list(chain(*self.recent_yfitted, y))\n",
    "\n",
    "        p_lane = np.polyfit(y_hist, x_hist, 2)\n",
    "        self.detected = self.sanity_check_lane(p_lane)\n",
    "        if self.detected:\n",
    "            self.current_fit = p_lane\n",
    "            x_fit = p_lane[0]*self.yvals**2 + p_lane[1]*self.yvals + p_lane[2]\n",
    "        \n",
    "            self.current_xfit = x_fit   # For drawing\n",
    "        \n",
    "            # Save current detected pixels\n",
    "            self.allx = np.array(x)\n",
    "            self.ally = np.array(y)\n",
    "\n",
    "            self.recent_xfitted.append(x_fit)\n",
    "            self.recent_yfitted.append(self.yvals)\n",
    "            if len(self.current_fit) > 1:\n",
    "                self.diffs = self.current_fit - p_lane\n",
    "        else:\n",
    "            print('Sanity check failed!')\n",
    "            # Use last fit if current one failed\n",
    "            p_lane = self.current_fit\n",
    "            x_fit = p_lane[0]*self.yvals**2 + p_lane[1]*self.yvals + p_lane[2]\n",
    "            \n",
    "        # Update ROI mask\n",
    "        self.mask.fill(0)\n",
    "        # http://stackoverflow.com/a/35902430/538379 \n",
    "        pts = np.transpose(np.vstack([x_fit, self.yvals])).reshape((-1,1,2)).astype(np.int32)\n",
    "        cv2.drawContours(self.mask, pts, -1, (255,255,255), thickness=100)\n",
    "        \n",
    "    \n",
    "    def sanity_check_lane(self, coeffs):\n",
    "        # Return true if there is no prior data\n",
    "        if self.radius_of_curvature is None:\n",
    "            return True\n",
    "        \n",
    "        A, B, _ = coeffs\n",
    "        y = self.img_size[0]/2   # Curvature at middle of image\n",
    "        R = (1 + (2*A*y + B)**2)**(3/2) / abs(2*A)\n",
    "        \n",
    "        k = 1/R   # Curvature is a better measure to track\n",
    "        current_k = 1/self.radius_of_curvature\n",
    "        \n",
    "        return abs(k-current_k)/current_k <= 0.01  # Max change from frame to frame is 1%\n",
    "            \n",
    "        \n",
    "    def detect_from_mask(self, lanes):\n",
    "        mask_lanes = cv2.bitwise_and(lanes, self.mask)\n",
    "#         y_pts, x_pts = np.nonzero(mask_lanes)\n",
    "        x_pts, y_pts = cv2.findNonZero(mask_lanes)\n",
    "        self.add_lane_pixels(x_pts, y_pts)\n",
    "        \n",
    "    def draw_lane(self, image):\n",
    "        \"\"\"\n",
    "        Draws lane on given image\n",
    "        \"\"\"\n",
    "        pts = np.array([np.transpose(np.vstack([self.current_xfit, self.yvals]))])\n",
    "        cv2.fillPoly(image, np.int_([pts]), (0,255, 0))\n",
    "        return image\n",
    "    \n",
    "def histogram_lane_detection(lanes, base_pts, num_bands = 50, window_width = 0.05):\n",
    "    \"\"\"Uses histogram and sliding window to detect lanes from scratch\"\"\"\n",
    "\n",
    "    height = lanes.shape[0]\n",
    "    band_height = int(1./num_bands * height)   # Divide image into horizontal bands\n",
    "    band_width = int(window_width*lanes.shape[1])\n",
    "    \n",
    "    l_x, l_y, r_x, r_y = [], [], [], []\n",
    "    \n",
    "    base_left, base_right = base_pts\n",
    "\n",
    "    idx_left, idx_right = base_pts\n",
    "    for i in reversed(range(num_bands)):\n",
    "        w_left = lanes[i*band_height:(i+1)*band_height,base_left-band_width//2:base_left+band_width//2]\n",
    "        w_right = lanes[i*band_height:(i+1)*band_height,base_right-band_width//2:base_right+band_width//2]\n",
    "        \n",
    "        left_y_pt, left_x_pt = np.nonzero(w_left)\n",
    "        right_y_pt, right_x_pt = np.nonzero(w_right)\n",
    "        \n",
    "        l_x.extend(left_x_pt + base_left-band_width//2)\n",
    "        l_y.extend(left_y_pt + i*band_height)\n",
    "        r_x.extend(right_x_pt+ base_right-band_width//2)\n",
    "        r_y.extend(right_y_pt+ i*band_height)\n",
    "\n",
    "        # Find 'x' with maximum nonzero elements as baseline for next window\n",
    "        s_left = np.sum(w_left, axis=0)\n",
    "        s_right = np.sum(w_right, axis=0)\n",
    "        if np.any(s_left > 0):\n",
    "            base_left = np.argmax(s_left) + base_left-band_width//2\n",
    "        if np.any(s_right > 0):\n",
    "            base_right = np.argmax(s_right) + base_right-band_width//2\n",
    "    \n",
    "    left_lane = Lane(base_left, lanes.shape)\n",
    "    right_lane = Lane(base_right, lanes.shape)\n",
    "    \n",
    "    left_lane.add_lane_pixels(l_x, l_y)\n",
    "    right_lane.add_lane_pixels(r_x, r_y)\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks_cwt\n",
    "\n",
    "def find_base_points(lanes, min_peak = 75.0):\n",
    "    \"\"\"Uses histogram to find possible base points for lane lines\"\"\"\n",
    "    hist = np.sum(lanes[int(lanes.shape[0]*0.5):,:], axis=0)\n",
    "    idx = find_peaks_cwt(hist, [100, 125, 150], max_distances=[100, 125, 150], noise_perc=50) \n",
    "\n",
    "    if len(idx) < 2:\n",
    "        return None\n",
    "\n",
    "    middle = np.average(idx)\n",
    "    left_pt = max(i for i in idx if i < middle)   # Closest peak to middle on the left\n",
    "    right_pt = min(i for i in idx if i >= middle) # Closest peak to middle on the right\n",
    "    return [left_pt, right_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 297 ms, sys: 36 ms, total: 333 ms\n",
      "Wall time: 259 ms\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-69e63da1281e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mclear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time process_image(image)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time process_image(image)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tantony/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tantony/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/tantony/anaconda/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tantony/anaconda/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-240-69e63da1281e>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(image, key_frame_interval, cache_length)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mleft_lane\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_lane\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistogram_lane_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mleft_lane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_from_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mright_lane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_from_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-239-3ee964defbb3>\u001b[0m in \u001b[0;36mdetect_from_mask\u001b[0;34m(self, lanes)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mmask_lanes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#         y_pts, x_pts = np.nonzero(mask_lanes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mx_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindNonZero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_lanes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lane_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "def process_image(image, key_frame_interval=2, cache_length=32):\n",
    "    global cam_mtx, cam_dist\n",
    "        \n",
    "    if process_image.cache is None:\n",
    "        warp_m, warp_minv = get_perspective_transform(image)\n",
    "                \n",
    "        cache = {'cam_mtx': cam_mtx,\n",
    "                 'cam_dist': cam_dist,\n",
    "                 'warp_m': warp_m,\n",
    "                 'warp_minv': warp_minv,\n",
    "                 'last_p_left': collections.deque(maxlen=cache_length),\n",
    "                 'last_p_right': collections.deque(maxlen=cache_length),\n",
    "                 'frame_ctr': 0,\n",
    "                 'left': None,\n",
    "                 'right': None,\n",
    "                 'base_pts': None}\n",
    "    else:\n",
    "        cache = process_image.cache\n",
    "    \n",
    "    \n",
    "    left_lane = cache['left']\n",
    "    right_lane = cache['right']\n",
    "\n",
    "    # Preprocess image and find edges using thresholding\n",
    "    undist = cv2.undistort(image, cam_mtx, cam_dist, None, cam_mtx)\n",
    "    edges = find_edges(undist)\n",
    "    lanes = cv2.warpPerspective(edges, cache['warp_m'], (edges.shape[1], edges.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base_pts = cache['base_pts']\n",
    "    if base_pts is None:\n",
    "        new_base_pts = find_base_points(lanes)\n",
    "        \n",
    "        if new_base_pts is not None:\n",
    "            base_pts = new_base_pts\n",
    "        else:\n",
    "            # Could not find new base points\n",
    "            # Re-use previous data if base points could not be found\n",
    "            cache['frame_ctr'] = cache['frame_ctr'] - 1 # Make sure we try again in the next frame\n",
    "            return undist\n",
    "\n",
    "    if (left_lane is None or not left_lane.detected) or (right_lane is None or not right_lane.detected):\n",
    "        # Detect from scratch\n",
    "        left_lane, right_lane = histogram_lane_detection(lanes, base_pts)\n",
    "    else:\n",
    "        left_lane.detect_from_mask(lanes)\n",
    "        right_lane.detect_from_mask(lanes)\n",
    "\n",
    "    cache['frame_ctr'] = cache['frame_ctr'] + 1\n",
    "    cache['base_pts'] = base_pts\n",
    "    process_image.cache = cache\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "    \n",
    "    yvals = left_lane.yvals\n",
    "    left_fitx = left_lane.current_xfit\n",
    "    right_fitx = right_lane.current_xfit\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "        \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, cache['warp_minv'], (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    cache['left'] = left_lane\n",
    "    cache['right'] = right_lane\n",
    "\n",
    "    return result\n",
    "\n",
    "def clear_cache():\n",
    "    process_image.cache = None\n",
    "    \n",
    "process_image.clear_cache = clear_cache\n",
    "clear_cache()\n",
    "%time process_image(image)\n",
    "%time process_image(image)\n",
    "out = process_image(image)\n",
    "plt.imshow(out)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vid_output = 'project_video_out.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c8c52827f295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvid_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time vid_clip.write_videofile(vid_output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clip' is not defined"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "vid_clip = clip.fl_image(process_image)\n",
    "%time vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_out.mp4\n",
      "[MoviePy] Writing video challenge_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [03:43<00:00,  1.68it/s]     | 1/485 [00:00<02:38,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_out.mp4 \n",
      "\n",
      "CPU times: user 3min 37s, sys: 31.8 s, total: 4min 9s\n",
      "Wall time: 3min 49s\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "vid_output = 'challenge_video_out.mp4'\n",
    "clip2 = VideoFileClip('challenge_video.mp4')\n",
    "vid_clip = clip2.fl_image(process_image)\n",
    "%time vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video harder_challenge_video_out.mp4\n",
      "[MoviePy] Writing video harder_challenge_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [10:45<00:00,  2.70it/s]    | 1/1200 [00:00<11:51,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: harder_challenge_video_out.mp4 \n",
      "\n",
      "CPU times: user 10min 31s, sys: 1min 44s, total: 12min 16s\n",
      "Wall time: 10min 49s\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "vid_output = 'harder_challenge_video_out.mp4'\n",
    "clip2 = VideoFileClip('harder_challenge_video.mp4')\n",
    "vid_clip = clip2.fl_image(process_image)\n",
    "%time vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"harder_challenge_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
