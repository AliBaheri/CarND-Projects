{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from math import *\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calibrate_camera(cal_images, nx, ny):\n",
    "    objpoints = []  # 3D points\n",
    "    imgpoints = []  # 2D points\n",
    "\n",
    "    objp = np.zeros((nx*ny,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    fname = cal_images[0]\n",
    "    for fname in cal_images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)\n",
    "    \n",
    "    return mtx, dist\n",
    "\n",
    "def camera_setup():\n",
    "    cal_images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    nx, ny = 9, 6\n",
    "    cam_mtx, cam_dist = calibrate_camera(cal_images, nx, ny)\n",
    "    return cam_mtx, cam_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform(image):\n",
    "    img_size = image.shape\n",
    "    src = np.array([[565. /1280.*img_size[1], 455./720.*img_size[0]],\n",
    "                    [725. /1280.*img_size[1], 455./720.*img_size[0]],\n",
    "                    [1130./1280.*img_size[1], 720./720.*img_size[0]],\n",
    "                    [190. /1280.*img_size[1], 720./720.*img_size[0]]], np.float32)\n",
    "\n",
    "    dst = np.array([[300. /1280.*img_size[1], 0.  /720.*img_size[0]],\n",
    "                    [1000./1280.*img_size[1], 0.  /720.*img_size[0]],\n",
    "                    [1000./1280.*img_size[1], 720./720.*img_size[0]],\n",
    "                    [300. /1280.*img_size[1], 720./720.*img_size[0]]], np.float32)\n",
    "\n",
    "    warp_m = cv2.getPerspectiveTransform(src, dst)\n",
    "    warp_minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return warp_m, warp_minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sobel(gray, orient='x', sobel_kernel=3):\n",
    "    return cv2.Sobel(gray, cv2.CV_64F, orient == 'x', orient == 'y', ksize=sobel_kernel)\n",
    "\n",
    "def abs_sobel_thresh(sobel, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    retval, output = cv2.threshold(scaled_sobel, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return output\n",
    "\n",
    "def mag_thresh(sobelx, sobely, thresh=(0, 255)):\n",
    "    # Calculate gradient magnitude\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    mag_sobel = (255*mag_sobel/np.max(mag_sobel)).astype(np.uint8)\n",
    "\n",
    "    retval, output = cv2.threshold(mag_sobel, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "    return output\n",
    "\n",
    "def dir_threshold(sobelx, sobely, thresh=(0, np.pi/2)):\n",
    "    # Here I'm suppressing annoying error messages\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        absgraddir = (np.absolute(np.arctan(sobely/sobelx)))\n",
    "        dir_binary =  np.zeros_like(absgraddir, dtype=np.uint8)\n",
    "        dir_binary[(absgraddir > thresh[0]) & (absgraddir < thresh[1])] = 1\n",
    "\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_edges(image, ksize = 11):\n",
    "    gray = cv2.equalizeHist(cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2GRAY))\n",
    "    hls = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    s = hls[:,:,2]\n",
    "#     h = hls[:,:,1]\n",
    "\n",
    "    sobelx = sobel(gray, orient='x', sobel_kernel=ksize)\n",
    "    gradx = abs_sobel_thresh(sobelx, thresh=(60, 70))\n",
    "\n",
    "    sobely = sobel(gray, orient='y', sobel_kernel=ksize)\n",
    "    grady = abs_sobel_thresh(sobely, thresh=(50, 120))\n",
    "    mag_binary = mag_thresh(sobelx, sobely, thresh=(50, 100))\n",
    "    _, gray_binary = cv2.threshold(gray.astype('uint8'), 120, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Check if gradx has sufficient data, else use magnitude\n",
    "    total_px = gradx.shape[0]*gradx.shape[1]/2\n",
    "    if len(np.nonzero(gradx[gradx.shape[0]/2:])[0])/total_px < 0.01:\n",
    "        mask_two = mag_binary\n",
    "    else:\n",
    "        mask_two = gradx\n",
    "    \n",
    "    _, s_binary = cv2.threshold(s.astype('uint8'), 125, 255, cv2.THRESH_BINARY)\n",
    "#     _, h_binary = cv2.threshold(h.astype('uint8'), 100, 200, cv2.THRESH_BINARY)\n",
    "#     color_binary = np.dstack(( mag_binary, h_binary, s_binary))#, h_binary))\n",
    "\n",
    "#     plt.subplot(1, 3, 1)\n",
    "#     plt.imshow(mask_two, cmap='gray')\n",
    "#     plt.subplot(1, 3, 2)\n",
    "#     plt.imshow(gradx, cmap='gray')\n",
    "#     plt.subplot(1, 3, 3)\n",
    "#     plt.imshow(mag_binary, cmap='gray')\n",
    "#     combined_binary = np.zeros_like(gray_binary)\n",
    "\n",
    "    combined_binary = np.clip(cv2.bitwise_and(gray_binary, cv2.bitwise_or(s_binary, mask_two)), 0, 1).astype('uint8')\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A, B, _ = p_left\n",
    "y = image.shape[0]\n",
    "R_left = (1 + (2*A*y + B)**2)**(3/2) / abs(2*A)\n",
    "# print(R_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cam_mtx, cam_dist = camera_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = mpimage.imread('test_images/test2a.jpg')\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "undist = cv2.undistort(image, cam_mtx, cam_dist, None, cam_mtx)\n",
    "edges = find_edges(undist)\n",
    "warp_m, warp_minv = get_perspective_transform(edges)\n",
    "lanes = cv2.warpPerspective(edges, warp_m, (edges.shape[1], edges.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "plt.rcParams['figure.figsize'] = figsize=(10,12)\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(undist)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(lanes, cmap='gray')\n",
    "base_pts = find_base_points(lanes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "import collections\n",
    "from itertools import chain, repeat\n",
    "    \n",
    "class Lane():\n",
    "    def __init__(self, base_pt, img_size):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = collections.deque(maxlen=10)\n",
    "        self.recent_yfitted = collections.deque(maxlen=10)\n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None   \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "        \n",
    "        self.current_xfit = None\n",
    "        self.roi_mask = None\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.base_pt = base_pt\n",
    "        \n",
    "        self.yvals = np.linspace(0, img_size[0], 101)\n",
    "        self.mask = np.ones(img_size, dtype=np.uint8)*255\n",
    "    \n",
    "    def add_lane_pixels(self, x, y):\n",
    "        # Use all pixels from previous detections for curve fit\n",
    "        x_hist = list(chain(*self.recent_xfitted, x))\n",
    "        y_hist = list(chain(*self.recent_yfitted, y))\n",
    "\n",
    "        p_lane = np.polyfit(y_hist, x_hist, 2)\n",
    "\n",
    "        x_fit = p_lane[0]*self.yvals**2 + p_lane[1]*self.yvals + p_lane[2]\n",
    "        \n",
    "        self.current_xfit = x_fit\n",
    "        \n",
    "        # Save current detected pixels\n",
    "        self.allx = np.array(x)\n",
    "        self.ally = np.array(y)\n",
    "\n",
    "        self.recent_xfitted.append(x_fit)\n",
    "        self.recent_yfitted.append(self.yvals)\n",
    "        if len(self.current_fit) > 1:\n",
    "            self.diffs = self.current_fit - p_lane\n",
    "\n",
    "        self.current_fit = p_lane\n",
    "        \n",
    "        # TODO: Add sanity check for fit\n",
    "        \n",
    "        # Update ROI mask\n",
    "        self.mask.fill(0)\n",
    "        # http://stackoverflow.com/a/35902430/538379 \n",
    "        pts = np.transpose(np.vstack([x_fit, self.yvals])).reshape((-1,1,2)).astype(np.int32)\n",
    "        cv2.drawContours(self.mask, pts, -1, (255,255,255), thickness=100)\n",
    "        \n",
    "        self.detected = True\n",
    "    \n",
    "    def detect_from_mask(self, lanes):\n",
    "        mask_lanes = cv2.bitwise_and(lanes, self.mask)\n",
    "        y_pts, x_pts = np.nonzero(mask_lanes)\n",
    "        self.add_lane_pixels(x_pts, y_pts)\n",
    "        \n",
    "    def draw_lane(self, image):\n",
    "        \"\"\"\n",
    "        Draws lane on given image\n",
    "        \"\"\"\n",
    "        pts = np.array([np.transpose(np.vstack([self.current_xfit, self.yvals]))])\n",
    "        cv2.fillPoly(image, np.int_([pts]), (0,255, 0))\n",
    "        return image\n",
    "    \n",
    "def histogram_lane_detection(lanes, base_pts, num_bands = 25, window_width = 0.05):\n",
    "    \"\"\"Uses histogram and sliding window to detect lanes from scratch\"\"\"\n",
    "\n",
    "#     plt.imshow(lanes)\n",
    "#     plt.show()\n",
    "    height = lanes.shape[0]\n",
    "    band_height = int(1./num_bands * height)   # Divide image into horizontal bands\n",
    "    band_width = int(window_width*lanes.shape[1])\n",
    "    \n",
    "    l_x, l_y, r_x, r_y = [], [], [], []\n",
    "    \n",
    "    base_left, base_right = base_pts\n",
    "\n",
    "    idx_left, idx_right = base_pts\n",
    "    for i in reversed(range(num_bands)):\n",
    "        w_left = lanes[i*band_height:(i+1)*band_height,base_left-band_width//2:base_left+band_width//2]\n",
    "        w_right = lanes[i*band_height:(i+1)*band_height,base_right-band_width//2:base_right+band_width//2]\n",
    "        \n",
    "        left_y_pt, left_x_pt = np.nonzero(w_left)\n",
    "        right_y_pt, right_x_pt = np.nonzero(w_right)\n",
    "        \n",
    "        l_x.extend(left_x_pt + base_left-band_width//2)\n",
    "        l_y.extend(left_y_pt + i*band_height)\n",
    "        r_x.extend(right_x_pt+ base_right-band_width//2)\n",
    "        r_y.extend(right_y_pt+ i*band_height)\n",
    "\n",
    "        # Find 'x' with maximum nonzero elements as baseline for next window\n",
    "        s_left = np.sum(w_left, axis=0)\n",
    "        s_right = np.sum(w_right, axis=0)\n",
    "        if np.any(s_left > 0):\n",
    "            base_left = np.argmax(s_left) + base_left-band_width//2\n",
    "        if np.any(s_right > 0):\n",
    "            base_right = np.argmax(s_right) + base_right-band_width//2\n",
    "    \n",
    "    left_lane = Lane(base_left, lanes.shape)\n",
    "    right_lane = Lane(base_right, lanes.shape)\n",
    "    \n",
    "    left_lane.add_lane_pixels(l_x, l_y)\n",
    "    right_lane.add_lane_pixels(r_x, r_y)\n",
    "    return left_lane, right_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks_cwt\n",
    "\n",
    "def find_base_points(lanes, min_peak = 75.0):\n",
    "    \"\"\"Uses histogram to find possible base points for lane lines\"\"\"\n",
    "    hist = np.sum(lanes[int(lanes.shape[0]*0.5):,:], axis=0)\n",
    "    idx = find_peaks_cwt(hist, [100, 125, 150], max_distances=[100, 125, 150], noise_perc=50) \n",
    "\n",
    "    if len(idx) < 2:\n",
    "        return None\n",
    "\n",
    "    middle = np.average(idx)\n",
    "    left_pt = max(i for i in idx if i < middle)   # Closest peak to middle on the left\n",
    "    right_pt = min(i for i in idx if i >= middle) # Closest peak to middle on the right\n",
    "    return [left_pt, right_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_image(image, key_frame_interval=2, cache_length=32):\n",
    "    global cam_mtx, cam_dist\n",
    "        \n",
    "    if process_image.cache is None:\n",
    "        warp_m, warp_minv = get_perspective_transform(image)\n",
    "                \n",
    "        cache = {'cam_mtx': cam_mtx,\n",
    "                 'cam_dist': cam_dist,\n",
    "                 'warp_m': warp_m,\n",
    "                 'warp_minv': warp_minv,\n",
    "                 'last_p_left': collections.deque(maxlen=cache_length),\n",
    "                 'last_p_right': collections.deque(maxlen=cache_length),\n",
    "                 'frame_ctr': 0,\n",
    "                 'left': None,\n",
    "                 'right': None,\n",
    "                 'base_pts': None}\n",
    "    else:\n",
    "        cache = process_image.cache\n",
    "    \n",
    "    \n",
    "    left_lane = cache['left']\n",
    "    right_lane = cache['right']\n",
    "\n",
    "    # Preprocess image and find edges using thresholding\n",
    "    undist = cv2.undistort(image, cam_mtx, cam_dist, None, cam_mtx)\n",
    "    edges = find_edges(undist)\n",
    "    lanes = cv2.warpPerspective(edges, cache['warp_m'], (edges.shape[1], edges.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    base_pts = cache['base_pts']\n",
    "    if cache['frame_ctr'] % key_frame_interval == 0 or base_pts is None:\n",
    "        new_base_pts = find_base_points(lanes)\n",
    "        \n",
    "        if new_base_pts is not None:\n",
    "            base_pts = new_base_pts\n",
    "        else:\n",
    "            # Could not find new base points\n",
    "            # Re-use previous data if base points could not be found\n",
    "            cache['frame_ctr'] = cache['frame_ctr'] - 1 # Make sure we try again in the next frame\n",
    "    \n",
    "    if base_pts is None: # And no cache exists\n",
    "        return undist\n",
    "\n",
    "    if (left_lane is None or not left_lane.detected) or (right_lane is None or not right_lane.detected):\n",
    "        # Detect from scratch\n",
    "        left_lane, right_lane = histogram_lane_detection(lanes, base_pts)\n",
    "    else:\n",
    "        left_lane.detect_from_mask(lanes)\n",
    "        right_lane.detect_from_mask(lanes)\n",
    "\n",
    "    cache['frame_ctr'] = cache['frame_ctr'] + 1\n",
    "    cache['base_pts'] = base_pts\n",
    "    process_image.cache = cache\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "    \n",
    "    yvals = left_lane.yvals\n",
    "    left_fitx = left_lane.current_xfit\n",
    "    right_fitx = right_lane.current_xfit\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "#     lane1_pts = np.int_([np.transpose(np.vstack([cache['left'].allx, cache['left'].ally]))])\n",
    "#     lane2_pts = np.int_([np.transpose(np.vstack([cache['right'].allx, cache['right'].ally]))])\n",
    "#     cv2.fillPoly(color_warp, np.int_([lane1_pts]), (255,0,0))\n",
    "#     cv2.fillPoly(color_warp, np.int_([lane2_pts]), (255,0,0))\n",
    "    \n",
    "#     color_warp[cache['left'].ally, cache['left'].allx,:] = (255,0,0)\n",
    "#     color_warp[cache['right'].ally, cache['right'].allx,:] = (0,0,255)\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, cache['warp_minv'], (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "#     plt.imshow(lanes, cmap='gray')\n",
    "#     plt.plot(left_fitx, yvals)\n",
    "#     plt.plot(right_fitx, yvals)\n",
    "#     plt.plot(cache['left'].allx, cache['left'].ally)\n",
    "#     plt.plot(cache['right'].allx, cache['right'].ally)\n",
    "#     plt.show()\n",
    "    cache['left'] = left_lane\n",
    "    cache['right'] = right_lane\n",
    "\n",
    "    return result\n",
    "\n",
    "def clear_cache():\n",
    "    process_image.cache = None\n",
    "    \n",
    "process_image.clear_cache = clear_cache\n",
    "clear_cache()\n",
    "# # %time process_image(image)\n",
    "# # %time process_image(image)\n",
    "# out = process_image(image)\n",
    "# plt.imshow(out)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vid_output = 'project_video_out.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_out.mp4\n",
      "[MoviePy] Writing video project_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [08:40<00:00,  2.63it/s]    | 1/1261 [00:00<05:40,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_out.mp4 \n",
      "\n",
      "CPU times: user 8min 49s, sys: 1min 35s, total: 10min 24s\n",
      "Wall time: 8min 43s\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "vid_clip = clip.fl_image(process_image)\n",
    "%time vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"project_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_video_out.mp4\n",
      "[MoviePy] Writing video challenge_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [02:56<00:00,  2.04it/s]     | 1/485 [00:00<02:02,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_video_out.mp4 \n",
      "\n",
      "CPU times: user 3min 9s, sys: 26.1 s, total: 3min 35s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "vid_output = 'challenge_video_out.mp4'\n",
    "clip2 = VideoFileClip('challenge_video.mp4')\n",
    "vid_clip = clip2.fl_image(process_image)\n",
    "%time vid_clip.write_videofile(vid_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"challenge_video_out.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(vid_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
