{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "tf.python.control_flow_ops = control_flow_ops\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './driving-data/'\n",
    "img_rows, img_cols = 160, 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    columns = ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
    "\n",
    "    print('Loading driving log ...')\n",
    "\n",
    "    driving_log = pd.read_csv(data_path+'driving_log.csv', names=columns)\n",
    "    num_rows = len(driving_log.index)\n",
    "\n",
    "    train_images = np.zeros((num_rows, img_rows, img_cols, 3))\n",
    "    train_steering = driving_log.as_matrix(['steering'])\n",
    "\n",
    "    for index, row in tqdm_notebook(driving_log.iterrows(), unit=' rows', total=num_rows):\n",
    "        fname = os.path.basename(row['center'])\n",
    "        # Normalized YUV\n",
    "        train_images[index] = imread(data_path+'IMG/'+fname, False, 'RGB').astype(np.float32)/255.\n",
    "\n",
    "    print('Loaded', num_rows, 'rows.')\n",
    "    return train_images, train_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading driving log ...\n",
      "\n",
      "Loaded 3685 rows.\n"
     ]
    }
   ],
   "source": [
    "X1_train, y1_train = load_data()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X1_train, y1_train, test_size=0.10, random_state=10)\n",
    "del X1_train, y1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5,border_mode='valid',\n",
    "                        input_shape=(img_rows, img_cols, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Convolution2D(64, 5, 5, subsample=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# opt = Adam(lr=1e-3)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3316 samples, validate on 369 samples\n",
      "Epoch 1/10\n",
      "3316/3316 [==============================] - 15s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 2/10\n",
      " 656/3316 [====>.........................] - ETA: 11s - loss: 0.0021 - mean_squared_error: 0.0021"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, batch_size=16, nb_epoch=10,\n",
    "    validation_data=(X_val, y_val), verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val, batch_size=16)\n",
    "np.hstack((y_pred, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"my_model_003.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('my_model_003.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "9e4e74d983cb43daabc443aec411bb9f": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
