{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from math import *\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "tf.python.control_flow_ops = control_flow_ops\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input, InputLayer\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import model_from_json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_generator(driving_log, data_path, normalizer=255.0, steering_shift=3., steering_max=25.):\n",
    "    driving_log = driving_log.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    for index, row in driving_log.iterrows():\n",
    "        fname  = os.path.basename(row['center'])\n",
    "        fname1 = os.path.basename(row['left'])\n",
    "        fname2 = os.path.basename(row['right'])\n",
    "        \n",
    "        img  = imread(data_path+'IMG/'+fname).astype(np.float32)\n",
    "        img1 = imread(data_path+'IMG/'+fname1).astype(np.float32)\n",
    "        img2 = imread(data_path+'IMG/'+fname2).astype(np.float32)\n",
    "        \n",
    "        yield img, np.float32(row['steering'])\n",
    "        yield img1, np.float32(row['steering'])+steering_shift/steering_max\n",
    "        yield img2, np.float32(row['steering'])-steering_shift/steering_max\n",
    "        \n",
    "        if abs(np.float32(row['steering'])) > 0.5/25.:\n",
    "            yield np.fliplr(img), -np.float32(row['steering'])\n",
    "        \n",
    "#         if abs(np.float32(row['steering'])-steering_shift/steering_max) > 1./25.:\n",
    "#             yield np.fliplr(img2), -(np.float32(row['steering'])-steering_shift/steering_max)\n",
    "\n",
    "#         if abs(np.float32(row['steering'])+steering_shift/steering_max) > 1./25.:\n",
    "#             yield np.fliplr(img1), -(np.float32(row['steering'])+steering_shift/steering_max)\n",
    "\n",
    "def batch_generator(driving_log, data_path, preprocess_fn = None, batch_size=32, *args, **kwargs):\n",
    "    num_rows = len(driving_log.index)\n",
    "    train_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    train_steering = np.zeros((batch_size,1))\n",
    "    ctr = None\n",
    "    while 1:        \n",
    "        for j in range(batch_size):\n",
    "            # Reset generator if over bounds\n",
    "            if ctr is None or ctr >= num_rows:\n",
    "                ctr = 0\n",
    "                images = image_generator(driving_log, data_path, *args, **kwargs)\n",
    "            train_images[j], train_steering[j] = next(images)\n",
    "            ctr += 1\n",
    "        if preprocess_fn is not None:\n",
    "            yield preprocess_fn(train_images), (train_steering+1.)/2.\n",
    "        else:\n",
    "            yield (train_images), (train_steering+1.)/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = './driving-data/'\n",
    "test_path = './test-data/'\n",
    "\n",
    "img_rows, img_cols = 160, 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10172\n",
      "1692\n"
     ]
    }
   ],
   "source": [
    "columns = ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
    "driving_log = pd.read_csv(data_path+'driving_log_trimmed.csv', names=columns)\n",
    "driving_log = driving_log.sample(frac=1).reset_index(drop=True) # Shuffle\n",
    "\n",
    "test_log = pd.read_csv(test_path+'driving_log.csv', names=columns)\n",
    "test_log = test_log.sample(frac=1).reset_index(drop=True) # Shuffle\n",
    "\n",
    "train_data = batch_generator(driving_log, data_path, preprocess_fn=preprocess_input, batch_size=32)\n",
    "val_data = batch_generator(test_log.sample(frac=0.1), test_path, preprocess_fn=preprocess_input, batch_size=32)\n",
    "test_data = batch_generator(test_log.sample(frac=0.9), test_path, preprocess_fn=preprocess_input, batch_size=32)\n",
    "print(len(driving_log))\n",
    "print(len(test_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 convolution2d_95\n",
      "2 batchnormalization_95\n",
      "3 convolution2d_96\n",
      "4 batchnormalization_96\n",
      "5 convolution2d_97\n",
      "6 batchnormalization_97\n",
      "7 maxpooling2d_4\n",
      "8 convolution2d_98\n",
      "9 batchnormalization_98\n",
      "10 convolution2d_99\n",
      "11 batchnormalization_99\n",
      "12 maxpooling2d_5\n",
      "13 convolution2d_103\n",
      "14 batchnormalization_103\n",
      "15 convolution2d_101\n",
      "16 convolution2d_104\n",
      "17 batchnormalization_101\n",
      "18 batchnormalization_104\n",
      "19 averagepooling2d_11\n",
      "20 convolution2d_100\n",
      "21 convolution2d_102\n",
      "22 convolution2d_105\n",
      "23 convolution2d_106\n",
      "24 batchnormalization_100\n",
      "25 batchnormalization_102\n",
      "26 batchnormalization_105\n",
      "27 batchnormalization_106\n",
      "28 mixed0\n",
      "29 convolution2d_110\n",
      "30 batchnormalization_110\n",
      "31 convolution2d_108\n",
      "32 convolution2d_111\n",
      "33 batchnormalization_108\n",
      "34 batchnormalization_111\n",
      "35 averagepooling2d_12\n",
      "36 convolution2d_107\n",
      "37 convolution2d_109\n",
      "38 convolution2d_112\n",
      "39 convolution2d_113\n",
      "40 batchnormalization_107\n",
      "41 batchnormalization_109\n",
      "42 batchnormalization_112\n",
      "43 batchnormalization_113\n",
      "44 mixed1\n",
      "45 convolution2d_117\n",
      "46 batchnormalization_117\n",
      "47 convolution2d_115\n",
      "48 convolution2d_118\n",
      "49 batchnormalization_115\n",
      "50 batchnormalization_118\n",
      "51 averagepooling2d_13\n",
      "52 convolution2d_114\n",
      "53 convolution2d_116\n",
      "54 convolution2d_119\n",
      "55 convolution2d_120\n",
      "56 batchnormalization_114\n",
      "57 batchnormalization_116\n",
      "58 batchnormalization_119\n",
      "59 batchnormalization_120\n",
      "60 mixed2\n",
      "61 convolution2d_122\n",
      "62 batchnormalization_122\n",
      "63 convolution2d_123\n",
      "64 batchnormalization_123\n",
      "65 convolution2d_121\n",
      "66 convolution2d_124\n",
      "67 batchnormalization_121\n",
      "68 batchnormalization_124\n",
      "69 maxpooling2d_6\n",
      "70 mixed3\n",
      "71 convolution2d_129\n",
      "72 batchnormalization_129\n",
      "73 convolution2d_130\n",
      "74 batchnormalization_130\n",
      "75 convolution2d_126\n",
      "76 convolution2d_131\n",
      "77 batchnormalization_126\n",
      "78 batchnormalization_131\n",
      "79 convolution2d_127\n",
      "80 convolution2d_132\n",
      "81 batchnormalization_127\n",
      "82 batchnormalization_132\n",
      "83 averagepooling2d_14\n",
      "84 convolution2d_125\n",
      "85 convolution2d_128\n",
      "86 convolution2d_133\n",
      "87 convolution2d_134\n",
      "88 batchnormalization_125\n",
      "89 batchnormalization_128\n",
      "90 batchnormalization_133\n",
      "91 batchnormalization_134\n",
      "92 mixed4\n",
      "93 convolution2d_139\n",
      "94 batchnormalization_139\n",
      "95 convolution2d_140\n",
      "96 batchnormalization_140\n",
      "97 convolution2d_136\n",
      "98 convolution2d_141\n",
      "99 batchnormalization_136\n",
      "100 batchnormalization_141\n",
      "101 convolution2d_137\n",
      "102 convolution2d_142\n",
      "103 batchnormalization_137\n",
      "104 batchnormalization_142\n",
      "105 averagepooling2d_15\n",
      "106 convolution2d_135\n",
      "107 convolution2d_138\n",
      "108 convolution2d_143\n",
      "109 convolution2d_144\n",
      "110 batchnormalization_135\n",
      "111 batchnormalization_138\n",
      "112 batchnormalization_143\n",
      "113 batchnormalization_144\n",
      "114 mixed5\n",
      "115 convolution2d_149\n",
      "116 batchnormalization_149\n",
      "117 convolution2d_150\n",
      "118 batchnormalization_150\n",
      "119 convolution2d_146\n",
      "120 convolution2d_151\n",
      "121 batchnormalization_146\n",
      "122 batchnormalization_151\n",
      "123 convolution2d_147\n",
      "124 convolution2d_152\n",
      "125 batchnormalization_147\n",
      "126 batchnormalization_152\n",
      "127 averagepooling2d_16\n",
      "128 convolution2d_145\n",
      "129 convolution2d_148\n",
      "130 convolution2d_153\n",
      "131 convolution2d_154\n",
      "132 batchnormalization_145\n",
      "133 batchnormalization_148\n",
      "134 batchnormalization_153\n",
      "135 batchnormalization_154\n",
      "136 mixed6\n",
      "137 convolution2d_159\n",
      "138 batchnormalization_159\n",
      "139 convolution2d_160\n",
      "140 batchnormalization_160\n",
      "141 convolution2d_156\n",
      "142 convolution2d_161\n",
      "143 batchnormalization_156\n",
      "144 batchnormalization_161\n",
      "145 convolution2d_157\n",
      "146 convolution2d_162\n",
      "147 batchnormalization_157\n",
      "148 batchnormalization_162\n",
      "149 averagepooling2d_17\n",
      "150 convolution2d_155\n",
      "151 convolution2d_158\n",
      "152 convolution2d_163\n",
      "153 convolution2d_164\n",
      "154 batchnormalization_155\n",
      "155 batchnormalization_158\n",
      "156 batchnormalization_163\n",
      "157 batchnormalization_164\n",
      "158 mixed7\n",
      "159 convolution2d_167\n",
      "160 batchnormalization_167\n",
      "161 convolution2d_168\n",
      "162 batchnormalization_168\n",
      "163 convolution2d_165\n",
      "164 convolution2d_169\n",
      "165 batchnormalization_165\n",
      "166 batchnormalization_169\n",
      "167 convolution2d_166\n",
      "168 convolution2d_170\n",
      "169 batchnormalization_166\n",
      "170 batchnormalization_170\n",
      "171 averagepooling2d_18\n",
      "172 mixed8\n",
      "173 convolution2d_175\n",
      "174 batchnormalization_175\n",
      "175 convolution2d_172\n",
      "176 convolution2d_176\n",
      "177 batchnormalization_172\n",
      "178 batchnormalization_176\n",
      "179 convolution2d_173\n",
      "180 convolution2d_174\n",
      "181 convolution2d_177\n",
      "182 convolution2d_178\n",
      "183 averagepooling2d_19\n",
      "184 convolution2d_171\n",
      "185 batchnormalization_173\n",
      "186 batchnormalization_174\n",
      "187 batchnormalization_177\n",
      "188 batchnormalization_178\n",
      "189 convolution2d_179\n",
      "190 batchnormalization_171\n",
      "191 mixed9_0\n",
      "192 merge_3\n",
      "193 batchnormalization_179\n",
      "194 mixed9\n",
      "195 convolution2d_184\n",
      "196 batchnormalization_184\n",
      "197 convolution2d_181\n",
      "198 convolution2d_185\n",
      "199 batchnormalization_181\n",
      "200 batchnormalization_185\n",
      "201 convolution2d_182\n",
      "202 convolution2d_183\n",
      "203 convolution2d_186\n",
      "204 convolution2d_187\n",
      "205 averagepooling2d_20\n",
      "206 convolution2d_180\n",
      "207 batchnormalization_182\n",
      "208 batchnormalization_183\n",
      "209 batchnormalization_186\n",
      "210 batchnormalization_187\n",
      "211 convolution2d_188\n",
      "212 batchnormalization_180\n",
      "213 mixed9_1\n",
      "214 merge_4\n",
      "215 batchnormalization_188\n",
      "216 mixed10\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model_1 = Model(input=base_model.input, output=base_model.get_layer('mixed8').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_path = './driving-data/IMG/center_2016_11_28_22_31_45_470.jpg'\n",
    "img = imread(img_path).astype(np.float32)\n",
    "x = preprocess_input(np.expand_dims(img, axis=0))\n",
    "\n",
    "base_features = base_model_1.predict(x)\n",
    "print(base_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,40)\n",
    "for i in range(64):\n",
    "    plt.subplot(16,4,i+1)\n",
    "    plt.imshow(base_features[0,:,:,i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, 3))\n",
    "# we chose to train the top 4 inception blocks, i.e. we will freeze\n",
    "# the first (136) layers and unfreeze the rest:\n",
    "for layer in base_model.layers[:114]:\n",
    "   layer.trainable = False\n",
    "for layer in base_model.layers[114:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dense(1000)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "x = Dense(100)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "steering_pred = Dense(1)(x)\n",
    "model = Model(input=base_model.input, output=steering_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1696/9600 [====>.........................] - ETA: 64s - loss: 0.0885"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(train_data, validation_data = val_data,\n",
    "                        samples_per_epoch = 9600,\n",
    "                        nb_val_samples = 960,\n",
    "                        nb_epoch=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inp = next(test_data)\n",
    "test_loss = model.predict(inp[0])\n",
    "# print(inp[0].shape)\n",
    "# print(inp[1].shape)\n",
    "# pred = model.predict(inp[0])\n",
    "# print(pred.shape)\n",
    "# d = abs(pred-inp[1])\n",
    "# print(d)\n",
    "# print(test_loss[3])\n",
    "# print(test_loss)\n",
    "# print(inp[1][-3,:].shape)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "model_name = 'model_i1'\n",
    "with open(model_name+'.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(model_name+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
